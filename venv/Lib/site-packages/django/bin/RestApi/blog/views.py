from django.shortcuts import render
from django.http import HttpResponse
from django.core import serializers
from .models import Paper, People
import json
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import pymysql
import re, math
from collections import Counter
from operator import itemgetter



WORD = re.compile(r'\w+')

def get_cosine(vec1, vec2):
     intersection = set(vec1.keys()) & set(vec2.keys())
     numerator = sum([vec1[x] * vec2[x] for x in intersection])

     sum1 = sum([vec1[x]**2 for x in vec1.keys()])
     sum2 = sum([vec2[x]**2 for x in vec2.keys()])
     denominator = math.sqrt(sum1) * math.sqrt(sum2)

     if not denominator:
        return 0.0
     else:
        return float(numerator) / denominator

def text_to_vector(text):
     words = WORD.findall(text)
     return Counter(words)


def largest(arr, n):
    max = arr[0]
    for i in range(1, n):
        if arr[i] > max:
            max = arr[i]
    return max






def index(request):
    return HttpResponse("Hello word!")

@csrf_exempt
def paper1(request):
   keywords = request.POST.get('kewords')
   all_paper = Paper.objects.all()
   all_paper_serialize = serializers.serialize('json',all_paper)
   all_paper_json = json.loads(all_paper_serialize)
   data = json.dumps(all_paper_json)
   return HttpResponse(data)

@csrf_exempt
def people1(request):
   keywords = request.POST.get('kewords')
   all_people = People.objects.all()
   all_people_serialize = serializers.serialize('json',all_people)
   all_people_json = json.loads(all_people_serialize)
   data = json.dumps(all_people_json)
   return HttpResponse(data)


@csrf_exempt
def peoplenew(request):
   keywords = request.POST.get('keywords')
   number = request.POST.get('number')
   db = pymysql.connect('localhost', 'root', 'y93723152a', 'raw_data')

   cursor = db.cursor()


   #sql = SELECT b.article_id as article_id,a.id as id,a.name as name,b.affiliation_name as aff_name,c.keyword as keyword, d.title as papertitle  FROM author as a, article_author as b,article_keyword as c,article as d WHERE a.id=b.author_id and b.article_id=c.article_id and c.article_id=d.id LIMIT 10000"""
   # LIMIT 1000
   """cursor.execute(sql)
   db.commit()
   rows = cursor.fetchall()"""

   sql = """SELECT b.author_id, group_concat(a.keyword separator ', ') as keywords
               FROM article_keyword as a, article_author as b
               WHERE a.article_id=b.article_id
               group by b.author_id"""
   cursor.execute(sql)
   db.commit()
   rows = cursor.fetchall()

   #data = list(rows)

   #all_people_serialize = serializers.serialize('json',all_people)
   """all_people_json = json.loads(all_people_serialize)
   data = json.dumps(all_people_json)
   db.close()"""
   #print(rows)

   ############################################ New  last item!!!!!!!!!!!!!!!!!!!!!!!!
   cosine=[0]*1000000
   rowNew = [0]*1000000

   i = 0
   vector1 = text_to_vector(keywords)
   for r in rows:
      vector2 = text_to_vector(r[1])
      if(get_cosine(vector1, vector2) >0):
          rowNew[i] = r
          cosine[i] = get_cosine(vector1, vector2)
          i = i + 1


       
   #cosine.sort(reverse = True)




   """for k, v in d.items():
       if v == 0:
           del d[k]"""

   data=sorted(range(len(cosine)), key=lambda k: cosine[k],reverse = True)
   ######################################################
   rowNew2 = [0] * int(number)
   m=0
   for r in data:
       rowNew2[m]=rowNew[r]
       m=m+1
       if m == int(number):
           break



   json_output = json.dumps(rowNew2)

   db.close()
   return HttpResponse(json_output)

@csrf_exempt
def papernew(request):
   keywords = request.POST.get('keywords')
   number = request.POST.get('number')
   db = pymysql.connect('localhost', 'root', 'y93723152a', 'raw_data')

   cursor = db.cursor()
   # cursor.execute("TRUNCATE TABLE baseuniversityprofile")

   """sql = SELECT b.article_id as article_id, a.name as name,b.affiliation_name as aff_name,c.keyword as keyword, d.title as papertitle,d.abstract as abstract,d.journal as journal,d.publisher as publisher  FROM author as a, article_author as b,article_keyword as c,article as d WHERE a.id=b.author_id and b.article_id=c.article_id and c.article_id=d.id LIMIT 100000"""
   """cursor.execute(sql)
   db.commit()
   rows = cursor.fetchall()"""

   sql = """SELECT article_id, group_concat(keyword separator ', ') as keywords
            FROM article_keyword
            group by article_id """
   cursor.execute(sql)
   db.commit()
   rows = cursor.fetchall()

   #all_people_serialize = serializers.serialize('json',all_people)
   """all_people_json = json.loads(all_people_serialize)
   data = json.dumps(all_people_json)
   db.close()"""
   #print(rows)

   cosine = [0] * 10000000
   rowNew = [0] * 10000000

   i = 0
   vector1 = text_to_vector(keywords)
   for r in rows:
       vector2 = text_to_vector(r[1])
       if (get_cosine(vector1, vector2) > 0):
           rowNew[i] = r
           cosine[i] = get_cosine(vector1, vector2)
           i = i + 1

   data = sorted(range(len(cosine)), key=lambda k: cosine[k], reverse=True)
   ######################################################
   rowNew2 = [0] * int(number)
   m = 0
   for r in data:
       rowNew2[m] = rowNew[r]
       m = m + 1
       if m == int(number):
           break

   json_output = json.dumps(rowNew2)
   #json_output = json.dumps(rows)
   db.close()
   return HttpResponse(json_output)
